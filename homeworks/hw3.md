### Genome Bioinformatics: Homework 3

**Course Code:** [Insert Course Code]

**Instructor:** [Aleksey Komissarov]

**Submission Date:** [Insert Due Date]

#### Objective:
To equip students with the practical skills needed to deploy and run bioinformatics workflows on high-performance computing clusters using SLURM and on cloud platforms like Google Cloud and Amazon Web Services (AWS). You'll learn to navigate and utilize these environments to handle compute-intensive tasks efficiently.

#### Instructions:
Complete the tasks outlined below and submit a detailed report of your process, findings, and any challenges you encountered. Include screenshots where applicable and ensure your documentation is clear and thorough.

---

### Task 1: Running Pipelines on SLURM
**Objective:** Learn to use the SLURM workload manager to schedule and manage jobs on a high-performance computing cluster.

#### Instructions:

1. **SLURM Basics:**
   - Provide a brief overview of what SLURM is and its role in managing computational workloads.
   - Include instructions on how to access a SLURM-managed cluster if one is available to you.

2. **Script Adaptation:**
   - Modify your existing pipeline scripts from Homework 3 to run as SLURM jobs. This might involve writing SLURM batch scripts with directives for resource allocation, job arrays, etc.

3. **Job Management:**
   - Demonstrate how to submit, monitor, and manage jobs on SLURM. Discuss strategies for troubleshooting and optimizing job performance.

#### Deliverables:
- SLURM batch scripts and a detailed report documenting the process of running your pipeline on a SLURM cluster.

---

### Task 2: Running Pipelines on Google Cloud
**Objective:** Gain hands-on experience with Google Cloud Platform (GCP) to run bioinformatics workflows.

#### Instructions:

1. **Google Cloud Setup:**
   - Provide a guide on setting up a Google Cloud account and navigating to the relevant services for running computational workloads (e.g., Compute Engine).

2. **Virtual Machine Configuration:**
   - Demonstrate how to configure and launch a virtual machine suitable for your pipeline. Discuss the selection of machine types, disk sizes, and operating systems.

3. **Running the Pipeline:**
   - Explain how to transfer your pipeline to the cloud environment and execute it. Include details on monitoring the run and accessing the results.

#### Deliverables:
- Step-by-step guide for running the pipeline on Google Cloud, including commands, configurations, and best practices.

---

### Task 3: Running Pipelines on Amazon Cloud (AWS)
**Objective:** Learn to deploy and manage bioinformatics workflows on Amazon Web Services.

#### Instructions:

1. **AWS Fundamentals:**
   - Provide an overview of AWS and its core services for compute tasks, such as EC2 and S3 for storage.

2. **EC2 Instance Setup:**
   - Guide on setting up an EC2 instance, including the selection of instance types, setting up security groups, and key pairs.

3. **Pipeline Deployment:**
   - Detail the process of transferring your pipeline to the EC2 instance, running it, and managing data with AWS services.

#### Deliverables:
- Comprehensive instructions for setting up and running the pipeline on AWS, along with any troubleshooting tips and considerations.

---

### Submission Guidelines:
- Compile your reports, scripts, and any additional notes or screenshots into a single document.
- Label each section clearly with detailed explanations and step-by-step instructions.
- Ensure clarity and accuracy in your documentation. Your work should enable someone else to replicate the process without prior knowledge of these platforms.

**Good luck, and enjoy harnessing the power of high-performance and cloud computing for genome bioinformatics!**
